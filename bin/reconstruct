#!/usr/bin/env python
import os.path, sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import numpy as np
import argparse
import json
from labmv import transformations as tf
from labmv import dataset
from labmv import features
from labmv import multiview
import networkx as nx
from networkx.algorithms import bipartite



def next_image_to_add(graph, recostruction, min_tracks=10):
    '''The non-reconstructed images that observes more reconstructed tracks.
    '''
    tracks, images = bipartite.sets(g)
    reconstructed_images = [i['id'] for i in reconstruction['shots']]
    reconstructed_points = [i['id'] for i in reconstruction['points']]
    max_tracks = 0
    best_image = None
    for image in images:
        if image not in reconstructed_images:
            common_tracks = 0
            for track in graph[image]:
                if track in reconstructed_points:
                    common_tracks += 1
            if max_tracks < common_tracks:
                max_tracks = common_tracks
                best_image = image
    if max_tracks >= min_tracks:
        return best_image
    else:
        return None

def rotate(angleaxis, point):
    angle = np.linalg.norm(angleaxis)
    if angle < 1e-8:
        return np.array(point)
    R = tf.rotation_matrix(angle, angleaxis)
    return R[:-1, :-1].dot(np.array(point))

def angleaxis(R):
    '''Compute angle-axis representation from a rotation matrix.
    '''
    T = np.identity(4)
    T[:3,:3] = R
    angle, direction, point = tf.rotation_from_matrix(T)
    return direction / np.linalg.norm(direction) * angle

def single_reprojection_error(camera, shot, point, observation):
    p = rotate(shot['rotation'], point['coordinates'])
    p += shot['translation']
    xp = p[0] / p[2]
    yp = p[1] / p[2]

    l1 = camera.get('k1', 0.0)
    l2 = camera.get('k2', 0.0)
    r2 = xp * xp + yp * yp;
    distortion = 1.0 + r2  * (l1 + l2  * r2)

    predicted_x = camera['focal'] * distortion * xp + camera['width'] / 2
    predicted_y = camera['focal'] * distortion * yp + camera['height'] / 2

    rx = predicted_x - observation[0]
    ry = predicted_y - observation[1]
    return np.sqrt(rx * rx + ry * ry)


def reprojection_error(graph, reconstruction):
    tracks, shots = bipartite.sets(g)
    reconstructed_cameras = {i['id']:i for i in reconstruction['cameras']}
    reconstructed_shots = {i['id']:i for i in reconstruction['shots']}
    reconstructed_points = {i['id']:i for i in reconstruction['points']}
    errors = []
    for shot_id in shots:
        if shot_id in reconstructed_shots:
            for track_id in graph[shot_id]:
                if track_id in reconstructed_points:
                    observation = graph[shot_id][track_id]['feature']
                    shot = reconstructed_shots[shot_id]
                    camera = reconstructed_cameras[shot['camera']]
                    point = reconstructed_points[track_id]
                    errors.append(single_reprojection_error(camera, shot, point, observation))
    return np.mean(errors)










parser = argparse.ArgumentParser(description='Compute reconstruction')
parser.add_argument('dataset',
                    help='path to the dataset to be processed')
args = parser.parse_args()


data = dataset.DataSet(args.dataset)
g = data.tracks_graph()

# Get the image connectivity graph.
track_nodes, image_nodes = bipartite.sets(g)
image_graph = bipartite.weighted_projected_graph(g, image_nodes)

# Choose a starting image pair.
best_pair = None
best_weight = 0
for im1, im2, d in image_graph.edges(data=True):
    if d['weight'] > best_weight:
        best_weight = d['weight']
        best_pair = (im1, im2)
im1, im2 = best_pair

print 'Matching image', im1, 'with image', im2

d1 = data.exif_data(im1)
d2 = data.exif_data(im2)
tracks, p1, p2 = dataset.common_tracks(g, im1, im2)

print 'Number of common tracks', len(tracks)

R, t, inliers, Xs = features.two_view_reconstruction(p1, p2, d1, d2)

print 'Number of inliers', len(inliers)

reconstruction = {
    "cameras": [
        {
            "id": "main_camera",
            "width": d1["width"],
            "height": d1["height"],
            "focal": d1["focal_ratio"] * d1["width"],
        },
    ],

    "shots" : [
        {
            "id": im1,
            "camera": "main_camera",
            "rotation": [0, 0, 0],
            "translation": [0, 0, 0],
        },
        {
            "id": im2,
            "camera": "main_camera",
            "rotation": list(angleaxis(R)),
            "translation": list(t),
        },
    ],

    "points" : [
        { 
            "id": tracks[inlier],
            "coordinates": X,
        } for inlier, X in zip(inliers, Xs)
    ]
}



print 'BEFORE', reprojection_error(g, reconstruction)
reconstruction = features.bundle(data.tracks_file(), reconstruction)
print 'AFTER', reprojection_error(g, reconstruction)


# TODO(pau): triangulate new tracks
# TODO(pau): implement a MLSE loss function for ceres.

next_image = next_image_to_add(g, reconstruction)
while next_image:
    print 'Adding {0} to the reconstruction'.format(next_image)

    reconstructed_tracks = {i['id']: i for i in reconstruction['points']}

    xs = []
    Xs = []
    for track in g[next_image]:
        if track in reconstructed_tracks:
            xs.append(g[next_image][track]['feature'])
            Xs.append(reconstructed_tracks[track]['coordinates'])
    x = np.array(xs)
    X = np.array(Xs)
    kernel = multiview.ResectionLinearKernel(x, X)
    P, inliers, error = multiview.ransac(kernel, 3)
    K, R, t = multiview.KRt_from_P(P)
    print len(inliers), len(x)

    reconstruction['shots'].append({
            "id": next_image,
            "camera": "main_camera",
            "rotation": list(angleaxis(R)),
            "translation": list(t),
        })


    print 'BEFORE', reprojection_error(g, reconstruction)
    reconstruction = features.bundle(data.tracks_file(), reconstruction)
    print 'AFTER', reprojection_error(g, reconstruction)

    if next_image == 'et008.jpg':
        break
    next_image = next_image_to_add(g, reconstruction)

with open(data.reconstruction_file(), 'w') as fout:
    fout.write(json.dumps(reconstruction, indent=4))

